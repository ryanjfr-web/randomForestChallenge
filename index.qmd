---
title: "Random Forest Challenge - Ryan Freer"
subtitle: "The Power of Weak Learners"
format:
  html: default
execute:
  echo: false
  eval: true
---

# ðŸŒ² Random Forest Challenge - The Power of Weak Learners

**What we know:** Individual decision trees are weak and have low accuracy or predictive power. Random forests are the combination of numerous weak trees that help to create a strong predictive model. However, if all these values are so weak, how will we know when to stop adding more trees to the forest? The analysis that follows will clear up this dilemma with linear regression and the understanding of the relationship between 

**Our Approach:** We'll compare random forests with different numbers of trees against linear regression and individual decision trees to understand the trade-offs between complexity and performance.
*
::: {.panel-tabset}

### R

```{r}
#| label: load-and-model-r
#| echo: true
#| message: false
#| warning: false

# Load libraries
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(randomForest))

# Load data
sales_data <- read.csv("https://raw.githubusercontent.com/flyaflya/buad442Fall2025/refs/heads/main/datasets/salesPriceData.csv")

# Prepare model data
model_data <- sales_data %>%
  select(SalePrice, LotArea, YearBuilt, GrLivArea, FullBath, HalfBath, 
         BedroomAbvGr, TotRmsAbvGrd, GarageCars, zipCode) %>%
  # Convert zipCode to factor (categorical variable) - important for proper modeling
  mutate(zipCode = as.factor(zipCode)) %>%
  na.omit()

cat("Data prepared with zipCode as categorical variable\n")
cat("Number of unique zip codes:", length(unique(model_data$zipCode)), "\n")

# Split data
set.seed(123)
train_indices <- sample(1:nrow(model_data), 0.8 * nrow(model_data))
train_data <- model_data[train_indices, ]
test_data <- model_data[-train_indices, ]

# Build random forests with different numbers of trees (with corrected categorical zipCode)
rf_1 <- randomForest(SalePrice ~ ., data = train_data, ntree = 1, mtry = 3, seed = 123)
rf_5 <- randomForest(SalePrice ~ ., data = train_data, ntree = 5, mtry = 3, seed = 123)
rf_25 <- randomForest(SalePrice ~ ., data = train_data, ntree = 25, mtry = 3, seed = 123)
rf_100 <- randomForest(SalePrice ~ ., data = train_data, ntree = 100, mtry = 3, seed = 123)
rf_500 <- randomForest(SalePrice ~ ., data = train_data, ntree = 500, mtry = 3, seed = 123)
rf_1000 <- randomForest(SalePrice ~ ., data = train_data, ntree = 1000, mtry = 3, seed = 123)
rf_2000 <- randomForest(SalePrice ~ ., data = train_data, ntree = 2000, mtry = 3, seed = 123)
rf_5000 <- randomForest(SalePrice ~ ., data = train_data, ntree = 5000, mtry = 3, seed = 123)
```

::: {.panel-tabset}

### R

```{r}
#| label: performance-comparison-r
#| echo: true
#| message: false
#| warning: false
#| fig-width: 10
#| fig-height: 6

# Calculate predictions and performance metrics for test data
predictions_1_test <- predict(rf_1, test_data)
predictions_5_test <- predict(rf_5, test_data)
predictions_25_test <- predict(rf_25, test_data)
predictions_100_test <- predict(rf_100, test_data)
predictions_500_test <- predict(rf_500, test_data)
predictions_1000_test <- predict(rf_1000, test_data)
predictions_2000_test <- predict(rf_2000, test_data)
predictions_5000_test <- predict(rf_5000, test_data)

# Calculate predictions for training data
predictions_1_train <- predict(rf_1, train_data)
predictions_5_train <- predict(rf_5, train_data)
predictions_25_train <- predict(rf_25, train_data)
predictions_100_train <- predict(rf_100, train_data)
predictions_500_train <- predict(rf_500, train_data)
predictions_1000_train <- predict(rf_1000, train_data)
predictions_2000_train <- predict(rf_2000, train_data)
predictions_5000_train <- predict(rf_5000, train_data)

# Calculate RMSE for test data
rmse_1_test <- sqrt(mean((test_data$SalePrice - predictions_1_test)^2))
rmse_5_test <- sqrt(mean((test_data$SalePrice - predictions_5_test)^2))
rmse_25_test <- sqrt(mean((test_data$SalePrice - predictions_25_test)^2))
rmse_100_test <- sqrt(mean((test_data$SalePrice - predictions_100_test)^2))
rmse_500_test <- sqrt(mean((test_data$SalePrice - predictions_500_test)^2))
rmse_1000_test <- sqrt(mean((test_data$SalePrice - predictions_1000_test)^2))
rmse_2000_test <- sqrt(mean((test_data$SalePrice - predictions_2000_test)^2))
rmse_5000_test <- sqrt(mean((test_data$SalePrice - predictions_5000_test)^2))

# Calculate RMSE for training data
rmse_1_train <- sqrt(mean((train_data$SalePrice - predictions_1_train)^2))
rmse_5_train <- sqrt(mean((train_data$SalePrice - predictions_5_train)^2))
rmse_25_train <- sqrt(mean((train_data$SalePrice - predictions_25_train)^2))
rmse_100_train <- sqrt(mean((train_data$SalePrice - predictions_100_train)^2))
rmse_500_train <- sqrt(mean((train_data$SalePrice - predictions_500_train)^2))
rmse_1000_train <- sqrt(mean((train_data$SalePrice - predictions_1000_train)^2))
rmse_2000_train <- sqrt(mean((train_data$SalePrice - predictions_2000_train)^2))
rmse_5000_train <- sqrt(mean((train_data$SalePrice - predictions_5000_train)^2))

# Calculate R-squared
r2_1 <- 1 - sum((test_data$SalePrice - predictions_1_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_5 <- 1 - sum((test_data$SalePrice - predictions_5_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_25 <- 1 - sum((test_data$SalePrice - predictions_25_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_100 <- 1 - sum((test_data$SalePrice - predictions_100_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_500 <- 1 - sum((test_data$SalePrice - predictions_500_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_1000 <- 1 - sum((test_data$SalePrice - predictions_1000_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_2000 <- 1 - sum((test_data$SalePrice - predictions_2000_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_5000 <- 1 - sum((test_data$SalePrice - predictions_5000_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)

# Create performance comparison
performance_df <- data.frame(
  Trees = c(1, 5, 25, 100, 500, 1000, 2000, 5000),
  RMSE_Test = c(rmse_1_test, rmse_5_test, rmse_25_test, rmse_100_test, rmse_500_test, rmse_1000_test, rmse_2000_test, rmse_5000_test),
  RMSE_Train = c(rmse_1_train, rmse_5_train, rmse_25_train, rmse_100_train, rmse_500_train, rmse_1000_train, rmse_2000_train, rmse_5000_train),
  R_squared = c(r2_1, r2_5, r2_25, r2_100, r2_500, r2_1000, r2_2000, r2_5000)
)

print(performance_df)
```

```{r}
#| label: rmse-plot
#| echo: false
#| fig-width: 10
#| fig-height: 6

# Create RMSE Plot
ggplot(performance_df, aes(x = Trees)) +
  geom_line(aes(y = RMSE_Train, color = "Training"), linewidth = 1.2) +
  geom_point(aes(y = RMSE_Train, color = "Training"), size = 2.5) +
  geom_line(aes(y = RMSE_Test, color = "Test"), linewidth = 1.2) +
  geom_point(aes(y = RMSE_Test, color = "Test"), size = 2.5) +
  scale_x_log10() +
  labs(
    title = "RMSE vs Number of Trees",
    subtitle = "Training vs Test Performance",
    x = "Number of Trees (log scale)",
    y = "RMSE",
    color = "Dataset"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11),
    legend.position = "right"
  )
```

```{r}
#| label: r-squared-plot
#| echo: false
#| fig-width: 10
#| fig-height: 6

# Create R-squared Plot
ggplot(performance_df, aes(x = Trees, y = R_squared)) +
  geom_line(color = "steelblue", linewidth = 1.2) +
  geom_point(color = "steelblue", size = 2.5) +
  scale_x_log10() +
  labs(
    title = "R-squared vs Number of Trees",
    subtitle = "Model Fit Improvement with More Trees",
    x = "Number of Trees (log scale)",
    y = "R-squared"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11)
  ) +
  ylim(0, 1)
```

### 3. Linear Regression vs Random Forest Comparison

**Your Task:** Compare random forests to linear regression baseline.

**Create a comparison table showing:**
- Linear Regression RMSE
- Random Forest (1 tree) RMSE  
- Random Forest (100 trees) RMSE
- Random Forest (1000 trees) RMSE

**Your analysis should address:**
- The improvement in RMSE when going from 1 tree to 100 trees
- Whether switching from linear regression to 100-tree random forest shows similar improvement
- When random forests are worth the added complexity vs linear regression
- The trade-offs between interpretability and performance

```{r}
#| label: linear-regression-comparison
#| echo: false

# Build linear regression model
lm_model <- lm(SalePrice ~ ., data = train_data)

# Calculate predictions for test data
lm_predictions <- predict(lm_model, test_data)

# Calculate RMSE for linear regression
lm_rmse <- sqrt(mean((test_data$SalePrice - lm_predictions)^2))

# Create comparison table
comparison_table <- data.frame(
  Model = c("Linear Regression", "Random Forest (1 tree)", "Random Forest (100 trees)", "Random Forest (1000 trees)"),
  RMSE = c(lm_rmse, rmse_1_test, rmse_100_test, rmse_1000_test)
)

# Print the comparison table
print(comparison_table)
```

**Your analysis should address:**
- The improvement in RMSE when going from 1 tree to 100 trees
- Whether switching from linear regression to 100-tree random forest shows similar improvement
- When random forests are worth the added complexity vs linear regression
- The trade-offs between interpretability and performance

::: {.callout-important}
## ðŸ“Š Comparison Requirements

Create a clear table comparing:

- Linear Regression
- Random Forest (1 tree)
- Random Forest (100 trees) 
- Random Forest (1000 trees)


### Questions to Answer for 75% Grade on Challenge

1. **Power of More Trees Analysis:** Provide a clear, well-reasoned analysis of how random forest performance improves with more trees. Your analysis should demonstrate understanding of ensemble learning principles and diminishing returns. 

The analysis of the data with the addition of more trees gets a lot stronger. It is much better with more trees than less trees, but adding too many will not necessarily make you data that much better. We can find an optimal range that will always give us the data we are looking for based on the knowlegde of random forests. 
### Questions to Answer for 85% Grade on Challenge

2. **Overfitting Analysis:** Provide a thorough analysis comparing decision trees vs random forests in terms of overfitting. Your analysis should explain why individual trees overfit while random forests don't, and the mechanisms that prevent overfitting in ensemble methods.

In decision trees, the training data will continually get better for however much depth you decide to add. However, it does not improve the test data and infact hinders it as more and more depth is added. It is not the same for the train and test data. 

### Questions to Answer for 95% Grade on Challenge

3. **Linear Regression Comparison:** Your analysis should include a clear comparison table and discussion of when random forests are worth the added complexity vs linear regression. Focus on practical implications for real-world applications.
